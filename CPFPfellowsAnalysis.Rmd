---
title: "MilestoneReportMWS"
author: "Martin Skarzynski"
date: "February 17, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Current CPFP Fellows Analysis


The first step is to download and read in the data. 

# Download and read in the data
The data are available at this url: https://cpfp.nci.nih.gov/about-us/fellows.txt

## Download the data

```{r}

## Download the raw data file...
## Unless you already have it in your working directory
if (!file.exists("fellows.txt")) {
  download.file("https://cpfp.nci.nih.gov/about-us/fellows.txt",
  destfile = paste(getwd(),"/fellows.txt", sep=""))
}
```

## I manually added in missing entries from the current fellows website
https://cpfp.nci.nih.gov/about-us/fellows.shtml
I named the new file fellows2.txt

## Load filepath into memory

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
## You can set your working directory to final/en_US...
## and then use the filenames (wrapped in quotes)...
## but I prefer to load the path into memory...
path<-paste(getwd(),"/fellows2.txt", sep="")
```

## Read in the data

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
## First, I will read in all of the data, but later I will take a subsample.
## The raw binary (rb) method was the only way I could read in the full news data set. 
## I skipped the embedded nuls in all, though these were only in the twitter data set.
con <- file(path, open="rb")
dat<-readLines(con, skipNul = TRUE, encoding = "ASCII")
close(con)
```

## Remove contact info

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}

dat2<-gsub("^Phone.{1,}|^Email.*|^Contact.*", "", dat, ignore.case = TRUE)

## Remove empty lines
dat3<-dat2[which(dat2!="")]
dat4<-dat3[which(dat3!=" ")]
## dat2<-dat[-which(dat=="")] #Alternative solution
```

## Make table of "Years of Entry"

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
year<- grep("^Year of entry.*", dat4, ignore.case = TRUE, value = TRUE)
year<-gsub("Year of entry ", "", year, ignore.case = TRUE)
year

yrtbl<-table(year)

yeardf<-as.data.frame(yrtbl)

names(yeardf) <- c("Year","Count")
```

## Generate dataframe of doctoral degrees and years the degrees were obtained

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}

doc<- grep("^Doctoral degree.*|PhD.*", dat4, ignore.case = TRUE, value = TRUE)
doc<-gsub("Doctoral degree ", "", doc, ignore.case = TRUE)

doc<- strsplit(doc, ",")
doc<- unlist(doc)
docyear<-grep("20..", doc, ignore.case = TRUE, value = TRUE)
docyear<-gsub("\\(|\\)|[a-z]| |\\.","", docyear, ignore.case = TRUE)

doc<-grep(".*University.*|.*College.*|.*Institute.*|.*School.*|.*Academy.*", doc, ignore.case = TRUE, value = TRUE)
doc<-gsub("^ |^  |\\(.*\\)", "", doc, ignore.case = TRUE)

docFinal<-cbind(doc,docyear)
docFinal<-as.data.frame(docFinal)
names(docFinal) <- c("University","docYear")
```

## Obtain doctoral degree counts by university

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
doctbl<-table(doc)
docyrtbl<-table(docyear)
docdf<-as.data.frame(doctbl)
docyrdf<-as.data.frame(docyrtbl)

names(docdf) <- c("University","Count")
```

## Generate dataframe of master degrees and years the degrees were obtained


```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
dat4
mph<-grep("^MPH |^MHS|^MSPH", dat4, ignore.case = FALSE, value = TRUE)
mph<-gsub("MPH |MHS, |^MSPH", "", mph, ignore.case = TRUE)
mphyear<- gsub("[^0-9]", "", mph)

mph<- strsplit(mph, ",")
mph<- unlist(mph)
mph<-gsub("/", "", mph, ignore.case = TRUE)
mph<-gsub("[^a-z A-Z]", "", mph, ignore.case = TRUE)
mph<-grep(".*University.*|.*College.*|.*Institute.*|.*School.*|.*Academy.*|NA", mph, ignore.case = TRUE, value = TRUE)
mph<-gsub("if applicable|Behavioral Sciences","", mph, ignore.case = TRUE)
mph<-gsub("^ +", "", mph)
mphyear

?getstr
mph
str


mphyear


mphFinal<-cbind(mph,mphyear)

mphFinal<-as.data.frame(mphFinal)
names(mphFinal) <- c("University","mphYear")
```

## Subset MPH degrees that Fellows obtained as postdocs 

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
include<- ifelse(docyear < mphyear,1,ifelse(docyear > mphyear,0,NA))

include<-as.data.frame(include)
docmphFinal<-cbind(docFinal,mphFinal)
mphFinal2<-cbind(mphFinal,include)
#for (i in 1:ncol(dat)){dat[,i]=as.vector(dat[,i])}).

mphFinal2<-mphFinal2[which(mphFinal2$include=="1"),]

mphFinal3<- mphFinal2[,-3]
```

## Obtain counts of master degree by university

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}

mphtbl<-table(mph)

mphdf<-as.data.frame(mphtbl)

names(mphdf) <- c("University","Count")

mphdf<-mphdf[which(mphdf$University!="NA"),]
```

## Obtain counts of master degree by university

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
mphtbl<-table(as.vector(mphFinal3[,1]))

mphdfFinal<-as.data.frame(mphtbl)

names(mphdfFinal) <- c("University","Count")

```

## Order data by count

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
yeardf<-yeardf[order(yeardf$Year,decreasing = TRUE),]
mphdf<-mphdf[order(mphdf$Count,decreasing = TRUE),]
mphdfFinal<-mphdfFinal[order(mphdfFinal$Count,decreasing = TRUE),]
docdf<-docdf[order(docdf$Count,decreasing = TRUE),]

names(mphFinal3) <- c("University","Year")
mphFinal3<-mphFinal3[order(mphFinal3$Year, mphFinal3$University,decreasing = FALSE),]


```

## Plot the mph data subset as pie charts

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
pack<-"plotly"
newPack <- pack[!(pack %in% installed.packages()[,"Package"])]
if(length(newPack)) install.packages(newPack)

library(plotly)

pmph <- plot_ly(mphdfFinal, labels = ~University, values = ~Count, type = 'pie') %>%
  layout(title = 'MPH programs completed by 1st year Cancer Prevention Fellows',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
pmph
htmlwidgets::saveWidget(as.widget(pmph), "mphPie.html")

```

## Present remaining data as tables

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
yeardf
docdf

```

## Obtain Research Interest data

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
pack<-c("tm","wordcloud")
newPack <- pack[!(pack %in% installed.packages()[,"Package"])]
if(length(newPack)) install.packages(newPack)
library(tm)
library(wordcloud)
dat4
RI <- grep("^Research Interests ", dat4, ignore.case = TRUE, value = TRUE)
RI<-gsub("Research Interests ", "", RI, ignore.case = TRUE)
```

## Clean Research Interest data

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}

RI<- removePunctuation(RI)
RI<- stripWhitespace(RI)
RI <- removeWords(RI, stopwords("english"))
RI <- removeWords(RI, "the")
RI<- tolower(RI)
```


#Tokenization
Here I put together lists of unigrams, bigrams and trigrams.

## Download ngram_tokenizer and tokenize

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}

## I was not able to install RWeka package, because of a java version problem.
## Instead of trying to figure it out, I used the ngram_tokenizer snippet
## created by Maciej Szymkiewicz, aka zero323 on Github.
if (!file.exists("ngram_tokenizer.R")) {
download.file("https://raw.githubusercontent.com/zero323/r-snippets/master/R/ngram_tokenizer.R", 
    destfile = paste(getwd(),"/ngram_tokenizer.R", sep=""))
}
source("ngram_Tokenizer.R")

unigram_tokenizer <- ngram_tokenizer(1)
uniList <- unigram_tokenizer(RI)
freqNames <- as.vector(names(table(unlist(uniList))))
freqCount <- as.numeric(table(unlist(uniList)))
dfUni <- data.frame(Word = freqNames,
                    Count = freqCount)
attach(dfUni)
dfUniSort<-dfUni[order(-Count),]
detach(dfUni)

bigram_tokenizer <- ngram_tokenizer(2)
biList <- bigram_tokenizer(RI)
freqNames <- as.vector(names(table(unlist(biList))))
freqCount <- as.numeric(table(unlist(biList)))
dfBi <- data.frame(Word = freqNames,
                    Count = freqCount)
attach(dfBi)
dfBiSort<-dfBi[order(-Count),]
detach(dfBi)

trigram_tokenizer <- ngram_tokenizer(3)
triList <- trigram_tokenizer(RI)
freqNames <- as.vector(names(table(unlist(triList))))
freqCount <- as.numeric(table(unlist(triList)))
dfTri <- data.frame(Word = freqNames,
                    Count = freqCount)
attach(dfTri)
dfTriSort<-dfTri[order(-Count),]
detach(dfTri)

quadgram_tokenizer <- ngram_tokenizer(4)
quadList <- quadgram_tokenizer(RI)
freqNames <- as.vector(names(table(unlist(quadList))))
freqCount <- as.numeric(table(unlist(quadList)))
dfQuad <- data.frame(Word = freqNames,
                    Count = freqCount)
attach(dfQuad)
dfQuadSort<-dfQuad[order(-Count),]
detach(dfQuad)

wordbank<-rbind(dfUniSort, dfBiSort, dfTriSort, dfQuadSort)

wordbank<-wordbank[order(wordbank$Count,decreasing = TRUE),]

head(wordbank, n=40)
```

## Create a wordcloud

```{r echo=TRUE, eval=TRUE, warning=FALSE, error=FALSE}
require(RColorBrewer)
set.seed(20170304)
colors <- brewer.pal(8, "Dark2")
pal <- colorRampPalette(colors)

wc1<-wordcloud(words = dfUniSort$Word, freq = dfUniSort$Count, min.freq = 1,
          max.words=40, random.order=FALSE, rot.per=0.35, ordered.colors = FALSE,
          colors=pal(40))
text(x=0.5, y=0, "Research Interest Word Cloud")


png("RIwordcloud.png", width=3, height=3, units="in", res=300)
wordcloud(words = dfUniSort$Word, freq = dfUniSort$Count, min.freq = 1,
          max.words=40, random.order=FALSE, rot.per=0.35, ordered.colors = FALSE,
          colors=pal(40))
dev.off()

```
# Unused code

## Preceptor and Branch info
PP <- grep("Primary Preceptor", dat4, ignore.case = TRUE, value = TRUE)
PP<-gsub("Primary Preceptor/Branch", "", PP, ignore.case = TRUE)

RI
PP

```






